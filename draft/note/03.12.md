Netty 字节流操作



### UUID

用过MongoDB的人会知道，MongoDB会自动给每一条数据赋予一个唯一的[ObjectId](https://docs.mongodb.com/manual/reference/method/ObjectId/),保证不会重复，这是怎么做到的呢？实际上它用的是一种UUID算法，生成的ObjectId占12个字节，由以下几个部分组成，

- 4个字节表示的Unix timestamp,
- 3个字节表示的机器的ID
- 2个字节表示的进程ID
- 3个字节表示的计数器

[UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier)是一类算法的统称，具体有不同的实现。UUID的有点是每台机器可以独立产生ID，理论上保证不会重复，所以天然是分布式的，缺点是生成的ID太长，不仅占用内存，而且索引查询效率低。



对象头 8 字节

1. 锁信息
2. hashcode
3. GC 标记



产生死锁的***\*四个必要条件\****：
（1） 互斥条件：一个资源每次只能被一个进程使用。
（2） 占有且等待：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
（3）不可强行占有:进程已获得的资源，在末使用完之前，不能强行剥夺。
（4） 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。
这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之

一不满足，就不会发生死锁。



NIO（Non-blocking IO）

NIO 与 传统 IO 相比，是非阻塞的

NIO 的数据读取时，通知系统将数据异步写入缓冲区，应用程序和缓冲区进行数据交互

NIO 在处理时，数据处理更加复杂，因为缓存区的数据并不是时刻处于可以被处理的状态；需要进行数据检查



分布式系统三个指标 CAP

* C 一致性
* A 可用性
* P 分区容错性

三个指标不可能同时成立

1. P 是分布式系统必备的，即有多个分区进行容错
2. 由于多个分区之间需要网络进行数据同步，而网络是不可靠的，如果数据同步的网络出现问题：
   1. 如果要保证 C 一致性，那么数据未同步的节点就不能提供服务，A 可用性不满足
   2. 如果要保证 A 可用性，那么数据未同步的节点数据仍然需要提供服务，但是数据不是最新的，C 一致性不满足



一致性 hash

* 传统 hash 路由：对 hash 值直接取模，得到路由的直接服务节点，这样会导致服务器数目变化时，取模基数改变，改变前和改变后取模的结果会大不一致，涉及到的数据迁移变化比较大

* 为了减少服务节点变化前后，对 hash 路由结果的影响，使用一致性 hash 进行节点路由

操作：

将 hash 值分布在一个圆环上，节点也对应 hash 在圆环上，把圆环切分成多个小段，每个节点负责小段，hash 路由到这个小段的请求，都由此节点负责

优点：

如果有节点添加或者删除，只会影响一个小段内的 hash 路由进行变更，大部分 hash 仍旧路由到原来的节点，不受影响





TCP/IP

分层：

* 应用层：HTTP
* 传输层：TCP/UDP
* 网络层：IP
* 数据链路层：MAC/数据包
* 物理层：网卡/电信号



数据包部分，经过层层封装，上层头部都添加在下层数据包中，以 HTTP 为例，最终包含：

1. 以太网首部：MAC 地址
2. 数据部分
   1. IP 首部
   2. TCP 首部
   3. HTTP 内容



